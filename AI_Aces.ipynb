{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShathuCodes/ModelX_Hackathon/blob/main/AI_Aces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import needed library"
      ],
      "metadata": {
        "id": "lSZUOWeY9erY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "31qqyvQPuBH3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq4BLSKe8_ws"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store data set as df"
      ],
      "metadata": {
        "id": "TXYdX9iY9w6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Dementia Prediction Dataset.zip\")"
      ],
      "metadata": {
        "id": "yx-bFJ789eE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "300EqkCJBnxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the needed coloums only"
      ],
      "metadata": {
        "id": "P83s4oNd97m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demographic_columns =  [\n",
        "    # Identifier and visit info\n",
        "    'NACCID', 'NACCADC', 'PACKET', 'FORMVER', 'VISITMO', 'VISITDAY', 'VISITYR',\n",
        "    'NACCVNUM', 'NACCAVST', 'NACCNVST',\n",
        "\n",
        "    # TARGET VARIABLE - Dementia Status\n",
        "    'DEMENTED',\n",
        "\n",
        "    # Alternative target variables (optional)\n",
        "    'NACCUDSD', 'NORMCOG', 'CDRGLOB',\n",
        "\n",
        "    # Demographics & Baseline\n",
        "    'NACCAGE', 'EDUC', 'SEX', 'NACCNIHR','AGE',\n",
        "\n",
        "    # Cognitive Test Scores\n",
        "    'NACCMMSE', 'NACCMOCA', 'ANIMALS', 'VEG', 'TRAILA', 'TRAILB',\n",
        "    'LOGIMEM', 'MEMUNITS', 'BOSTON', 'DIGIF', 'DIGIB',\n",
        "\n",
        "    # Functional Assessment (FAQ)\n",
        "    'BILLS', 'TAXES', 'SHOPPING', 'GAMES', 'STOVE', 'MEALPREP',\n",
        "    'EVENTS', 'PAYATIN', 'REMDATES', 'TRAVEL',\n",
        "\n",
        "    # Clinical Dementia Rating (CDR)\n",
        "    'CDRSUM', 'CDRGLOB', 'MEMORY', 'ORIENT', 'JUDGMENT',\n",
        "    'COMMUN', 'HOMEHOBB', 'PERSCARE',\n",
        "\n",
        "    # Neuropsychiatric Symptoms (NPI-Q)\n",
        "    'DEL', 'HALL', 'AGIT', 'DEPD', 'ANX', 'ELAT', 'APA',\n",
        "    'DISN', 'IRR', 'MOT', 'NITE', 'APP',\n",
        "\n",
        "    # Clinician Judgment of Symptoms\n",
        "    'COGMEM', 'COGORI', 'COGIUDG', 'COGLANG', 'COGVIS', 'COGATTN',\n",
        "\n",
        "    # Medical History\n",
        "    'CVHATT', 'CVAFIB', 'CBSTROKE', 'CBTIA', 'DIABETES',\n",
        "    'HYPERTEN', 'HYPERCHO', 'DEP2YRS', 'NACCTBI',\n",
        "\n",
        "    # Family History\n",
        "    'NACCFAM'\n",
        "    \"TOBAC30\", \"TOBAC100\", \"SMOKYRS\",\n",
        "    \"ALCOCCAS\", \"ALCFREQ\",\n",
        "    \"DIABETES\", \"INDEPEND\", \"RESIDENC\", \"MARISTAT\", \"NACCLIVS\", \"HANDED\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "hsCQn90Y-CPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[col for col in demographic_columns if col in df.columns]]\n",
        "df"
      ],
      "metadata": {
        "id": "rd3x6PTC_8m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df[['NACCMMSE','SEX','ANIMALS','VEG','LOGIMEM','DEMENTED', 'NACCAGE','EDUC',  \"TOBAC100\", \"SMOKYRS\",\n",
        "    \"ALCOCCAS\", \"ALCFREQ\",\"DIABETES\", \"INDEPEND\", \"RESIDENC\", \"MARISTAT\", \"NACCLIVS\", \"HANDED\"]]"
      ],
      "metadata": {
        "id": "d_ux47JePkrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean NACCMMSE col"
      ],
      "metadata": {
        "id": "xNBE-6U5VjvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) LIST of all variables\n",
        "all_cols = [\n",
        "    # Cognitive tests\n",
        "    \"NACCMMSE\", \"LOGIMEM\", \"ANIMALS\", 'VEG',\n",
        "\n",
        "    # Core demographics\n",
        "    \"SEX\", \"NACCAGE\", \"EDUC\",\n",
        "\n",
        "    # Lifestyle / history\n",
        "    \"TOBAC100\", \"SMOKYRS\", \"ALCOCCAS\", \"ALCFREQ\",\n",
        "\n",
        "    # Categorical variables\n",
        "    \"DIABETES\", \"INDEPEND\", \"RESIDENC\",\n",
        "    \"MARISTAT\", \"NACCLIVS\", \"HANDED\" , 'DEMENTED'\n",
        "]\n",
        "\n",
        "\n",
        "# 2) VALIDATION RULES for each variable\n",
        "validation_rules = {\n",
        "\n",
        "    # Cognitive tests\n",
        "    \"NACCMMSE\":  lambda s: s.between(0, 30),\n",
        "    \"LOGIMEM\":   lambda s: s.between(0, 25),\n",
        "    \"ANIMALS\":   lambda s: s.between(0, 77),\n",
        "\n",
        "    # Sex\n",
        "    \"SEX\":       lambda s: s.isin([0, 1, 2]),   # we convert 2->0 later\n",
        "\n",
        "    # Numerical demographics\n",
        "    \"NACCAGE\":   lambda s: s.between(10, 100),\n",
        "    \"EDUC\":      lambda s: s.between(0, 36),\n",
        "\n",
        "    # Lifestyle\n",
        "    \"TOBAC100\":  lambda s: s.isin([0, 1]),\n",
        "    \"SMOKYRS\":   lambda s: s.between(0, 88),\n",
        "    \"ALCOCCAS\":  lambda s: s.isin([0, 1]),\n",
        "    \"ALCFREQ\":   lambda s: s.between(0, 8),\n",
        "\n",
        "    # Categorical with invalid codes 9, -4\n",
        "    \"DIABETES\":    lambda s: s.isin([0, 1, 2, 3]),\n",
        "    \"INDEPEND\":  lambda s: s.isin([1, 2, 3, 4]),\n",
        "    \"RESIDENC\":  lambda s: s.isin([1, 2, 3, 4]),\n",
        "    \"MARISTAT\":  lambda s: s.isin([1, 2, 3, 4, 5, 6]),\n",
        "    \"NACCLIVS\":  lambda s: s.isin([1, 2, 3, 4, 5]),\n",
        "    \"HANDED\":    lambda s: s.isin([1, 2, 3]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "3SkiJe73SGvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = df[all_cols].copy()\n",
        "df_sub[\"SEX\"] = df_sub[\"SEX\"].replace(2, 0)\n",
        "mask = np.ones(len(df_sub), dtype=bool)\n",
        "\n",
        "for col, rule in validation_rules.items():\n",
        "    if col not in df_sub.columns:\n",
        "        print(f\"Warning: Column '{col}' not found in dataframe. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        result = rule(df_sub[col])\n",
        "        mask &= result.fillna(False)\n",
        "    except Exception as e:\n",
        "        print(f\" Error while validating {col}: {e}\")\n",
        "df_valid = df_sub[mask].copy()\n",
        "df_valid.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "CdJHrrDLhNXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid = df_valid.loc[:, ~df_valid.columns.duplicated()]\n"
      ],
      "metadata": {
        "id": "CvjnC2ztmc7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid"
      ],
      "metadata": {
        "id": "sjgFkZPRZFzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cw9pfKO-dalW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid['NACCMMSE'] = (30 - df_valid['NACCMMSE']) / 30\n",
        "df_valid['ANIMALS']  = (77 - df_valid['ANIMALS']) / 77\n",
        "df_valid['LOGIMEM']  = (25 - df_valid['LOGIMEM']) / 25\n",
        "df_valid['VEG']      = (77 - df_valid['VEG']) / 77\n",
        "\n",
        "df_valid['SMOKYRS']   = df_valid['SMOKYRS'] / df_valid['SMOKYRS'].max()\n",
        "df_valid['ALCOCCAS']  = df_valid['ALCOCCAS'] / df_valid['ALCOCCAS'].max()\n",
        "df_valid['ALCFREQ']   = df_valid['ALCFREQ'] / df_valid['ALCFREQ'].max()\n",
        "df_valid['TOBAC100']  = df_valid['TOBAC100'].astype(int)\n",
        "\n",
        "df_valid['NACCAGE'] = df_valid['NACCAGE'] / df_valid['NACCAGE'].max()\n",
        "df_valid['EDUC'] = (df_valid['EDUC'].max() - df_valid['EDUC']) / df_valid['EDUC'].max()\n",
        "\n",
        "df_valid['DIABETES'] = df_valid['DIABETES'] / 3\n",
        "df_valid['INDEPEND'] = (df_valid['INDEPEND'] - 1) / 3\n",
        "df_valid['RESIDENC'] = (df_valid['RESIDENC'] - 1) / 3\n",
        "\n",
        "df_valid.head(10)\n"
      ],
      "metadata": {
        "id": "VAxpNsexbEnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_valid['DEMENTED'])"
      ],
      "metadata": {
        "id": "zdQEp-0We7Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X = df_valid[[\"NACCMMSE\", \"LOGIMEM\", \"ANIMALS\", \"VEG\", \"SEX\",\"NACCAGE\", \"EDUC\", \"TOBAC100\", \"SMOKYRS\", \"ALCOCCAS\",\"ALCFREQ\", \"DIABETES\", \"INDEPEND\", \"RESIDENC\",\n",
        "    \"MARISTAT\", \"NACCLIVS\", \"HANDED\"]].values  # shape (n_samples, n_features)\n",
        "y = df_valid['DEMENTED'].values.reshape(-1,1)  # shape (n_samples, 1)\n",
        "\n",
        "# Add bias term (intercept)\n",
        "X = np.hstack([np.ones((X.shape[0],1)), X])  # shape (n_samples, n_features+1)\n",
        "\n",
        "# Feature scaling\n",
        "X_mean = X[:,1:].mean(axis=0)\n",
        "X_std = X[:,1:].std(axis=0)\n",
        "X[:,1:] = (X[:,1:] - X_mean) / X_std"
      ],
      "metadata": {
        "id": "hjSmv_j5ffzV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n"
      ],
      "metadata": {
        "id": "p3zdWnULfnOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(y, y_pred):\n",
        "    m = y.shape[0]\n",
        "    epsilon = 1e-8\n",
        "    loss = - (1/m) * np.sum(y*np.log(y_pred+epsilon) + (1-y)*np.log(1-y_pred+epsilon))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "EdJxPlFVfoVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize weights\n",
        "n_features = X.shape[1]\n",
        "weights = np.zeros((n_features,1))\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "iterations = 5000\n",
        "m = X.shape[0]\n",
        "\n",
        "# History lists for plotting\n",
        "loss_history = []\n",
        "accuracy_history = []\n",
        "iteration_steps = []\n",
        "\n",
        "for i in range(iterations):\n",
        "    # Forward pass\n",
        "    z = np.dot(X, weights)\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Compute gradient\n",
        "    gradient = (1/m) * np.dot(X.T, (y_pred - y))\n",
        "\n",
        "    # Update weights\n",
        "    weights -= learning_rate * gradient\n",
        "\n",
        "    # Store loss and accuracy for plotting at specified intervals\n",
        "    if i % 50 == 0: # Store every 50 iterations for a smoother plot without too much data\n",
        "        current_loss = compute_loss(y, y_pred)\n",
        "        y_pred_class_current = (y_pred >= 0.5).astype(int)\n",
        "        current_accuracy = np.mean(y_pred_class_current == y)\n",
        "\n",
        "        loss_history.append(current_loss)\n",
        "        accuracy_history.append(current_accuracy)\n",
        "        iteration_steps.append(i)\n",
        "\n",
        "    # Print loss occasionally\n",
        "    if i % 500 == 0:\n",
        "        print(f\"Iteration {i}, Loss: {current_loss:.4f}, Accuracy: {current_accuracy:.4f}\")\n",
        "\n",
        "# Plotting the loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(iteration_steps, loss_history, label='Training Loss')\n",
        "plt.title('Loss over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(iteration_steps, accuracy_history, label='Training Accuracy', color='orange')\n",
        "plt.title('Accuracy over Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PNWJrGglfsmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability of dementia\n",
        "y_prob = sigmoid(np.dot(X, weights))\n",
        "\n",
        "# Binary prediction\n",
        "y_pred_class = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = np.mean(y_pred_class == y)\n",
        "print(\"Training Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "1ByMlUmZf2Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "model_data = {\n",
        "    'weights': weights,\n",
        "    'X_mean': X_mean,\n",
        "    'X_std': X_std\n",
        "}\n",
        "\n",
        "with open(\"dementia_model.p\", \"wb\") as f:\n",
        "    pickle.dump(model_data, f)\n",
        "print(\"Model saved as dementia_model.p\")\n"
      ],
      "metadata": {
        "id": "4Bbt_ceViiVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"weights shape:\", weights.shape)\n",
        "print(\"X_mean shape:\", X_mean.shape)\n",
        "print(\"X_std shape:\", X_std.shape)\n"
      ],
      "metadata": {
        "id": "hv6anTLjmuUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X columns:\")\n",
        "print(df_valid.columns)\n"
      ],
      "metadata": {
        "id": "smmUh0OfmznX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_user_input(weights, X_mean, X_std):\n",
        "\n",
        "    print(\"\\nEnter values for prediction (press ENTER for mean):\\n\")\n",
        "\n",
        "    # RAW feature names (same order as training)\n",
        "    feature_names = [\n",
        "        \"NACCMMSE\",\"LOGIMEM\",\"ANIMALS\",\"VEG\",\n",
        "        \"SEX\",\"NACCAGE\",\"EDUC\",\n",
        "        \"TOBAC100\",\"SMOKYRS\",\"ALCOCCAS\",\"ALCFREQ\",\n",
        "        \"DIABETES\",\"INDEPEND\",\"RESIDENC\",\n",
        "        \"MARISTAT\",\"NACCLIVS\",\"HANDED\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    prompts = [\n",
        "        \"Please enter your memory & thinking test score (0–30): \",\n",
        "        \"Please enter your logical memory score (0–25): \",\n",
        "        \"How many animals can you name within one minute? (0–77): \",\n",
        "        \"How many vegetables can you name within one minute? (0–77): \",\n",
        "\n",
        "        \"What is your sex? (0 = Female, 1 = Male): \",\n",
        "        \"What is your age? (10–100): \",\n",
        "        \"How many years of formal education have you completed? (0–36): \",\n",
        "\n",
        "        \"Have you smoked at least 100 cigarettes in your life? (0 = No, 1 = Yes): \",\n",
        "        \"For how many total years have you smoked? (0–88): \",\n",
        "        \"Do you drink alcohol occasionally? (0 = No, 1 = Yes): \",\n",
        "        \"How often do you drink alcohol? (0 = Never to 8 = Daily): \",\n",
        "\n",
        "        \"What is your diabetes status? (0=None, 1=Adult onset, 2=Childhood onset, 3=Unknown): \",\n",
        "        \"What is your level of independence? (1=Independent, 2=Some help, 3=Needs help, 4=Fully dependent): \",\n",
        "        \"What is your living situation? (1=House, 2=Apartment, 3=Assisted living, 4=Nursing home): \",\n",
        "        \"What is your marital status? (1=Married, 2=Widowed, 3=Divorced, 4=Separated, 5=Never married, 6=Other): \",\n",
        "        \"Who do you currently live with? (1=Alone, 2=Spouse, 3=Family, 4=Friends, 5=Other): \",\n",
        "        \"Are you right-handed, left-handed, or ambidextrous? (1=Right, 2=Left, 3=Both): \"\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "    raw_means = np.zeros(17)\n",
        "\n",
        "    raw_means[0] = 30 - X_mean[0] * 30\n",
        "    raw_means[1] = 25 - X_mean[1] * 25\n",
        "    raw_means[2] = 77 - X_mean[2] * 77\n",
        "    raw_means[3] = 77 - X_mean[3] * 77\n",
        "    raw_means[4] = X_mean[4]\n",
        "    raw_means[5] = X_mean[5] * 110\n",
        "    raw_means[6] = 36 - X_mean[6] * 36\n",
        "    raw_means[7] = X_mean[7]\n",
        "    raw_means[8] = X_mean[8] * 88\n",
        "    raw_means[9] = X_mean[9]\n",
        "    raw_means[10] = X_mean[10] * 8\n",
        "    raw_means[11] = X_mean[11] * 3\n",
        "    raw_means[12] = X_mean[12] * 3 + 1\n",
        "    raw_means[13] = X_mean[13] * 3 + 1\n",
        "    raw_means[14] = X_mean[14]\n",
        "    raw_means[15] = X_mean[15]\n",
        "    raw_means[16] = X_mean[16]\n",
        "\n",
        "\n",
        "    user_vals = []\n",
        "\n",
        "    for i, feat in enumerate(feature_names):\n",
        "\n",
        "        default_val = raw_means[i]\n",
        "        raw = input(f\"{prompts[i]} (default={default_val}): \")\n",
        "\n",
        "        if raw.strip() == \"\":\n",
        "            user_vals.append(default_val)\n",
        "        else:\n",
        "            try:\n",
        "\n",
        "                if feat in [\"SEX\",\"TOBAC100\",\"ALCOCCAS\",\"DIABETES\",\n",
        "                            \"INDEPEND\",\"RESIDENC\",\"MARISTAT\",\"NACCLIVS\",\"HANDED\"]:\n",
        "                    user_vals.append(int(raw))\n",
        "                else:\n",
        "                    user_vals.append(float(raw))\n",
        "            except:\n",
        "                print(\"Invalid entry → using mean\")\n",
        "                user_vals.append(default_val)\n",
        "\n",
        "\n",
        "    processed = np.array([\n",
        "        (30 - user_vals[0]) / 30,\n",
        "        (25 - user_vals[1]) / 25,\n",
        "        (77 - user_vals[2]) / 77,\n",
        "        (77 - user_vals[3]) / 77,\n",
        "\n",
        "        user_vals[4],\n",
        "        user_vals[5] / 110,\n",
        "        (36 - user_vals[6]) / 36,\n",
        "\n",
        "        user_vals[7],\n",
        "        user_vals[8] / 88,\n",
        "        user_vals[9],\n",
        "        user_vals[10] / 8,\n",
        "\n",
        "        user_vals[11] / 3,\n",
        "        (user_vals[12] - 1) / 3,\n",
        "        (user_vals[13] - 1) / 3,\n",
        "\n",
        "        user_vals[14],\n",
        "        user_vals[15],\n",
        "        user_vals[16]\n",
        "    ])\n",
        "\n",
        "\n",
        "    x_scaled = (processed - X_mean) / X_std\n",
        "    x_final = np.insert(x_scaled, 0, 1)\n",
        "\n",
        "    prob = sigmoid(np.dot(x_final, weights))\n",
        "    prob = float(prob.item())\n",
        "\n",
        "    cls = int(prob >= 0.5)\n",
        "\n",
        "    print(\"\\n---------------------------\")\n",
        "    print(\"Predicted Probability:\", prob)\n",
        "    print(\"Predicted Class:\", cls)\n",
        "    print(\"(1 = Demented, 0 = Not Demented)\")\n",
        "    print(\"---------------------------\")\n",
        "predict_user_input(weights, X_mean, X_std)"
      ],
      "metadata": {
        "id": "9niT_TMY9-YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hksfh1kIYs8N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}